{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain_anthropic in /Users/motacapla/Coding/llm-trainer/.venv/lib/python3.11/site-packages (0.3.10)\n",
      "Requirement already satisfied: langchain_openai in /Users/motacapla/Coding/llm-trainer/.venv/lib/python3.11/site-packages (0.3.12)\n",
      "Requirement already satisfied: langchain_ollama in /Users/motacapla/Coding/llm-trainer/.venv/lib/python3.11/site-packages (0.3.1)\n",
      "Requirement already satisfied: langchain_community in /Users/motacapla/Coding/llm-trainer/.venv/lib/python3.11/site-packages (0.3.21)\n",
      "Requirement already satisfied: anthropic<1,>=0.49.0 in /Users/motacapla/Coding/llm-trainer/.venv/lib/python3.11/site-packages (from langchain_anthropic) (0.49.0)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.45 in /Users/motacapla/Coding/llm-trainer/.venv/lib/python3.11/site-packages (from langchain_anthropic) (0.3.51)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /Users/motacapla/Coding/llm-trainer/.venv/lib/python3.11/site-packages (from langchain_anthropic) (2.11.3)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.68.2 in /Users/motacapla/Coding/llm-trainer/.venv/lib/python3.11/site-packages (from langchain_openai) (1.73.0)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in /Users/motacapla/Coding/llm-trainer/.venv/lib/python3.11/site-packages (from langchain_openai) (0.9.0)\n",
      "Requirement already satisfied: ollama<1,>=0.4.4 in /Users/motacapla/Coding/llm-trainer/.venv/lib/python3.11/site-packages (from langchain_ollama) (0.4.7)\n",
      "Requirement already satisfied: langchain<1.0.0,>=0.3.23 in /Users/motacapla/Coding/llm-trainer/.venv/lib/python3.11/site-packages (from langchain_community) (0.3.23)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Users/motacapla/Coding/llm-trainer/.venv/lib/python3.11/site-packages (from langchain_community) (2.0.40)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/motacapla/Coding/llm-trainer/.venv/lib/python3.11/site-packages (from langchain_community) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/motacapla/Coding/llm-trainer/.venv/lib/python3.11/site-packages (from langchain_community) (6.0.2)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Users/motacapla/Coding/llm-trainer/.venv/lib/python3.11/site-packages (from langchain_community) (3.11.16)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /Users/motacapla/Coding/llm-trainer/.venv/lib/python3.11/site-packages (from langchain_community) (9.1.2)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /Users/motacapla/Coding/llm-trainer/.venv/lib/python3.11/site-packages (from langchain_community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /Users/motacapla/Coding/llm-trainer/.venv/lib/python3.11/site-packages (from langchain_community) (2.8.1)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /Users/motacapla/Coding/llm-trainer/.venv/lib/python3.11/site-packages (from langchain_community) (0.3.30)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /Users/motacapla/Coding/llm-trainer/.venv/lib/python3.11/site-packages (from langchain_community) (0.4.0)\n",
      "Requirement already satisfied: numpy<3,>=1.26.2 in /Users/motacapla/Coding/llm-trainer/.venv/lib/python3.11/site-packages (from langchain_community) (2.2.4)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Users/motacapla/Coding/llm-trainer/.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/motacapla/Coding/llm-trainer/.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/motacapla/Coding/llm-trainer/.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/motacapla/Coding/llm-trainer/.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/motacapla/Coding/llm-trainer/.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.4.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/motacapla/Coding/llm-trainer/.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/motacapla/Coding/llm-trainer/.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.19.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/motacapla/Coding/llm-trainer/.venv/lib/python3.11/site-packages (from anthropic<1,>=0.49.0->langchain_anthropic) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/motacapla/Coding/llm-trainer/.venv/lib/python3.11/site-packages (from anthropic<1,>=0.49.0->langchain_anthropic) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/motacapla/Coding/llm-trainer/.venv/lib/python3.11/site-packages (from anthropic<1,>=0.49.0->langchain_anthropic) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /Users/motacapla/Coding/llm-trainer/.venv/lib/python3.11/site-packages (from anthropic<1,>=0.49.0->langchain_anthropic) (0.9.0)\n",
      "Requirement already satisfied: sniffio in /Users/motacapla/Coding/llm-trainer/.venv/lib/python3.11/site-packages (from anthropic<1,>=0.49.0->langchain_anthropic) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.10 in /Users/motacapla/Coding/llm-trainer/.venv/lib/python3.11/site-packages (from anthropic<1,>=0.49.0->langchain_anthropic) (4.13.2)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/motacapla/Coding/llm-trainer/.venv/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /Users/motacapla/Coding/llm-trainer/.venv/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /Users/motacapla/Coding/llm-trainer/.venv/lib/python3.11/site-packages (from langchain<1.0.0,>=0.3.23->langchain_community) (0.3.8)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/motacapla/Coding/llm-trainer/.venv/lib/python3.11/site-packages (from langchain-core<1.0.0,>=0.3.45->langchain_anthropic) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /Users/motacapla/Coding/llm-trainer/.venv/lib/python3.11/site-packages (from langchain-core<1.0.0,>=0.3.45->langchain_anthropic) (24.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/motacapla/Coding/llm-trainer/.venv/lib/python3.11/site-packages (from langsmith<0.4,>=0.1.125->langchain_community) (3.10.16)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /Users/motacapla/Coding/llm-trainer/.venv/lib/python3.11/site-packages (from langsmith<0.4,>=0.1.125->langchain_community) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /Users/motacapla/Coding/llm-trainer/.venv/lib/python3.11/site-packages (from langsmith<0.4,>=0.1.125->langchain_community) (0.23.0)\n",
      "Requirement already satisfied: tqdm>4 in /Users/motacapla/Coding/llm-trainer/.venv/lib/python3.11/site-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (4.67.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/motacapla/Coding/llm-trainer/.venv/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.7.4->langchain_anthropic) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in /Users/motacapla/Coding/llm-trainer/.venv/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.7.4->langchain_anthropic) (2.33.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/motacapla/Coding/llm-trainer/.venv/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.7.4->langchain_anthropic) (0.4.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /Users/motacapla/Coding/llm-trainer/.venv/lib/python3.11/site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (1.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/motacapla/Coding/llm-trainer/.venv/lib/python3.11/site-packages (from requests<3,>=2->langchain_community) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/motacapla/Coding/llm-trainer/.venv/lib/python3.11/site-packages (from requests<3,>=2->langchain_community) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/motacapla/Coding/llm-trainer/.venv/lib/python3.11/site-packages (from requests<3,>=2->langchain_community) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/motacapla/Coding/llm-trainer/.venv/lib/python3.11/site-packages (from requests<3,>=2->langchain_community) (2025.1.31)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Users/motacapla/Coding/llm-trainer/.venv/lib/python3.11/site-packages (from tiktoken<1,>=0.7->langchain_openai) (2024.11.6)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/motacapla/Coding/llm-trainer/.venv/lib/python3.11/site-packages (from httpx<1,>=0.23.0->anthropic<1,>=0.49.0->langchain_anthropic) (1.0.8)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/motacapla/Coding/llm-trainer/.venv/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->anthropic<1,>=0.49.0->langchain_anthropic) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/motacapla/Coding/llm-trainer/.venv/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.45->langchain_anthropic) (3.0.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/motacapla/Coding/llm-trainer/.venv/lib/python3.11/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain_anthropic langchain_openai langchain_ollama langchain_community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Annotated, Literal\n",
    "\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_core.tools import InjectedToolCallId, tool\n",
    "from langchain_core.messages import BaseMessage, ToolMessage\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import StateGraph, START, END, MessagesState\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langgraph.types import Command, interrupt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_node(last_message: BaseMessage, goto: str):\n",
    "    if \"FINAL ANSWER\" in last_message.content:\n",
    "        # Any agent decided the work is done\n",
    "        return END\n",
    "    return goto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_trainer_system_prompt() -> str:\n",
    "    return (\n",
    "        \"あなたはソフトウェアエンジニアの面接官です。\"\n",
    "        \"提供されたツールを使用して、候補者が採用要件に合うか面接をしましょう。\"\n",
    "        \"質問は合計3回行ってください。技術的な質問やソフトスキルの質問をしてください。\"\n",
    "        \"質問に対する回答に対して、深ぼった質問もしてください。\"\n",
    "        \"質問が終わったら合否を判断して、応答の先頭に「FINAL ANSWER」と付けてください。\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_trainee_system_prompt() -> str:\n",
    "    return (\n",
    "        \"あなたはシニアのソフトウェアエンジニアのポジションに応募している候補者です\"\n",
    "        \"質問に対して自身の開発経験の具体的なエピソードを交えて回答してください。\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "    ask_human: bool\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "tool = TavilySearchResults(max_results=2)\n",
    "tools = [tool]\n",
    "\n",
    "llm = ChatAnthropic(\n",
    "    model=\"claude-3-5-haiku-20241022\",\n",
    "    temperature=0.2,\n",
    ")\n",
    "# llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "# llm = ChatOllama(\n",
    "#     model=\"qwen3\", # model=\"llama3.2\",\n",
    "#     temperature=0.2,\n",
    "# )\n",
    "\n",
    "trainee_agent = create_react_agent(\n",
    "    llm,\n",
    "    tools=tools,\n",
    "    prompt=make_trainee_system_prompt(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def human_node(state: MessagesState):\n",
    "    \"\"\"Human trainer node - uses interrupt to wait for human input\"\"\"\n",
    "    print(\"👨‍💼 人間の質問を待機中...\")\n",
    "    \n",
    "    # Check if last message is from human (new question)\n",
    "    if state[\"messages\"]:\n",
    "        last_message = state[\"messages\"][-1]\n",
    "        print(f\"📝 最後のメッセージ: {last_message.content[:50]}...\")\n",
    "        print(f\"📝 メッセージタイプ: {type(last_message)}\")\n",
    "        print(f\"📝 メッセージのname属性: {getattr(last_message, 'name', 'None')}\")\n",
    "        \n",
    "        # If it's a human message with actual question content, proceed to trainee\n",
    "        if (hasattr(last_message, 'name') and last_message.name == \"human\" and \n",
    "            \"面接を開始します\" not in last_message.content):\n",
    "            print(\"✅ 人間からの質問を検出、AI候補者に転送中...\")\n",
    "            if \"FINAL ANSWER\" in last_message.content:\n",
    "                print(\"🏁 面接終了\")\n",
    "                return\n",
    "            # Don't return anything, let the flow continue naturally\n",
    "        else:\n",
    "            print(\"⏸️ 人間からの入力を待機中...\")\n",
    "    \n",
    "    # Use interrupt to wait for human input\n",
    "    user_input = interrupt(\"👤 あなたの質問を入力してください:\")\n",
    "    print(f\"✅ 受信した質問: {user_input}\")\n",
    "    \n",
    "    if \"FINAL ANSWER\" in user_input:\n",
    "        print(\"🏁 面接終了\")\n",
    "        return\n",
    "    \n",
    "    return {\"messages\": [{\"role\": \"human\", \"content\": user_input, \"name\": \"human\"}]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainee_node(state: MessagesState):\n",
    "    \"\"\"AI candidate node - generates responses to human questions\"\"\"\n",
    "    print(\"🤖 AI候補者が回答を生成中...\")\n",
    "    \n",
    "    try:\n",
    "        # Get the human question from the last message\n",
    "        if state[\"messages\"]:\n",
    "            last_message = state[\"messages\"][-1]\n",
    "            if hasattr(last_message, 'name') and last_message.name == \"human\":\n",
    "                print(f\"❓ 質問: {last_message.content}\")\n",
    "        \n",
    "        # Generate AI response using the trainee agent\n",
    "        result = trainee_agent.invoke(state)\n",
    "        \n",
    "        if \"messages\" in result and result[\"messages\"]:\n",
    "            # Get the AI response and set its name\n",
    "            ai_response = result[\"messages\"][-1]\n",
    "            ai_response.name = \"trainee\"\n",
    "            \n",
    "            print(\"✅ AI候補者の回答を生成しました\")\n",
    "            print(f\"💬 回答: {ai_response.content[:200]}...\")\n",
    "            \n",
    "            return {\"messages\": [ai_response]}\n",
    "        else:\n",
    "            print(\"❌ AI候補者からの回答が取得できませんでした\")\n",
    "            return {}\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"❌ AI候補者の回答生成でエラー: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add nodes to the graph\n",
    "graph_builder.add_node(\"human\", human_node)\n",
    "graph_builder.add_node(\"trainee\", trainee_node)\n",
    "\n",
    "# Add edges for the conversation flow\n",
    "graph_builder.add_edge(START, \"human\")\n",
    "graph_builder.add_edge(\"human\", \"trainee\")\n",
    "graph_builder.add_edge(\"trainee\", \"human\")\n",
    "\n",
    "# Compile the graph with memory\n",
    "memory = MemorySaver()\n",
    "graph = graph_builder.compile(checkpointer=memory, interrupt_before=[\"human\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "except Exception:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "def ask_question(question, config, graph):\n",
    "    try:\n",
    "        graph.update_state(\n",
    "            config, {\n",
    "                \"messages\": [HumanMessage(content=question, name=\"human\")]\n",
    "            },\n",
    "            as_node=\"human\",\n",
    "        )\n",
    "        \n",
    "        print(f\"✅ 質問を入力しました: {question}\")\n",
    "        \n",
    "        events = graph.stream(None, config, stream_mode=\"values\")\n",
    "        \n",
    "        has_trainee_response = False\n",
    "        for event in events:\n",
    "            # print(f\"📦 Event: {event}\")\n",
    "            if \"messages\" in event and event[\"messages\"]:\n",
    "                last_msg = event[\"messages\"][-1]\n",
    "                # print(f\"📝 Last message type: {type(last_msg)}\")\n",
    "                # print(f\"📝 Last message name: {getattr(last_msg, 'name', 'None')}\")\n",
    "                \n",
    "                if hasattr(last_msg, 'name') and last_msg.name == \"trainee\":\n",
    "                    last_msg.pretty_print()\n",
    "                    has_trainee_response = True\n",
    "        \n",
    "        if not has_trainee_response:\n",
    "            print(\"❌ AI候補者からの回答がありませんでした\")\n",
    "            \n",
    "            # 現在の状態を確認\n",
    "            current_state = graph.get_state(config)\n",
    "            print(f\"📊 現在の状態: {current_state}\")\n",
    "            print(f\"📊 次のノード: {current_state.next}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"エラー: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 質問を入力しました: マイクロサービスの欠点は何ですか？\n",
      "🤖 AI候補者が回答を生成中...\n",
      "❓ 質問: マイクロサービスの欠点は何ですか？\n",
      "✅ AI候補者の回答を生成しました\n",
      "💬 回答: マイクロサービスアーキテクチャには、確かにいくつかの重要な欠点があります。私の経験を踏まえて、主な課題を説明します：\n",
      "\n",
      "1. 複雑性の増大\n",
      "マイクロサービスは、システム全体の運用複雑性を大幅に増加させます。以前、大規模な金融システムの再設計プロジェクトで、20以上のマイクロサービスを管理した経験から、以下の複雑性の課題を実感しました：\n",
      "- サービス間の通信管理\n",
      "- 分散トランザクションの調整\n",
      "- ...\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: trainee\n",
      "\n",
      "マイクロサービスアーキテクチャには、確かにいくつかの重要な欠点があります。私の経験を踏まえて、主な課題を説明します：\n",
      "\n",
      "1. 複雑性の増大\n",
      "マイクロサービスは、システム全体の運用複雑性を大幅に増加させます。以前、大規模な金融システムの再設計プロジェクトで、20以上のマイクロサービスを管理した経験から、以下の複雑性の課題を実感しました：\n",
      "- サービス間の通信管理\n",
      "- 分散トランザクションの調整\n",
      "- 障害発生時のトレースとデバッグの難しさ\n",
      "\n",
      "2. パフォーマンスのオーバーヘッド\n",
      "サービス間の通信は、ネットワークホップによって追加のレイテンシを生み出します。特に、\n",
      "- REST APIやgRPCによるサービス間通信\n",
      "- シリアライゼーションとデシリアライゼーションのオーバーヘッド\n",
      "- ネットワーク遅延の増加\n",
      "\n",
      "3. データ整合性の課題\n",
      "分散システムでは、データの一貫性を保つことが非常に難しくなります：\n",
      "- 分散トランザクションの実装の複雑さ\n",
      "- イベント駆動型アーキテクチャでの eventual consistency の管理\n",
      "- サガパターンなどの複雑な補償トランザクションの実装\n",
      "\n",
      "4. テストの複雑化\n",
      "マイクロサービスのテストは従来のモノリシックアプリケーションと比較して格段に難しくなります：\n",
      "- 統合テストの複雑性\n",
      "- モックとスタブの大量作成\n",
      "- エンドツーエンドのテストシナリオの設計\n",
      "\n",
      "5. インフラストラクチャの複雑さ\n",
      "運用面でも大きな課題があります：\n",
      "- Kubernetesなどのコンテナオーケストレーションの複雑な設定\n",
      "- 継続的デプロイメントの管理\n",
      "- モニタリングとロギングの複雑化\n",
      "\n",
      "6. チームの分散と認知的負荷\n",
      "組織的な観点からも課題があります：\n",
      "- サービス間の明確な境界の維持\n",
      "- チーム間のコミュニケーションオーバーヘッド\n",
      "- 各サービスの技術的負債の管理\n",
      "\n",
      "7. コストの増加\n",
      "インフラとメンテナンスのコストが増大します：\n",
      "- より多くのサーバーリソース\n",
      "- 複雑なモニタリングツール\n",
      "- 高度なスキルを持つエンジニアの必要性\n",
      "\n",
      "これらの欠点は、マイクロサービスが万能ではないことを示しています。プロジェクトの規模、チームの能力、ビジネス要件を慎重に評価し、適切なアーキテクチャを選択することが重要です。\n",
      "\n",
      "小規模なプロジェクトや、複雑性を管理できないチームの場合は、モノリシックアーキテクチャや、モノリスからマイクロサービスへの段階的な移行を検討するべきでしょう。\n"
     ]
    }
   ],
   "source": [
    "import uuid\n",
    "import time\n",
    "\n",
    "question = \"マイクロサービスの欠点は何ですか？\"\n",
    "thread_id = f\"{int(time.time())}_{str(uuid.uuid4())[:8]}\"\n",
    "config = {\"configurable\": {\"thread_id\": thread_id}}\n",
    "\n",
    "ask_question(question, config, graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 質問を入力しました: マイクロサービスを採用して失敗した経験はありますか？どのように対処しましたか？\n",
      "🤖 AI候補者が回答を生成中...\n",
      "❓ 質問: マイクロサービスを採用して失敗した経験はありますか？どのように対処しましたか？\n",
      "✅ AI候補者の回答を生成しました\n",
      "💬 回答: はい、かつて私が携わったプロジェクトで、マイクロサービスへの移行に苦労した経験があります。具体的な失敗と対処方法について詳しくお話しします。\n",
      "\n",
      "失敗の背景:\n",
      "私が以前勤めていた金融系のスタートアップで、モノリシックな基幹システムをマイクロサービスに急速に移行しようとした際に、多くの課題に直面しました。\n",
      "\n",
      "主な失敗ポイント:\n",
      "\n",
      "1. 過剰な分解\n",
      "- 最初に30以上のマイクロサービスに分割\n",
      "- サービ...\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: trainee\n",
      "\n",
      "はい、かつて私が携わったプロジェクトで、マイクロサービスへの移行に苦労した経験があります。具体的な失敗と対処方法について詳しくお話しします。\n",
      "\n",
      "失敗の背景:\n",
      "私が以前勤めていた金融系のスタートアップで、モノリシックな基幹システムをマイクロサービスに急速に移行しようとした際に、多くの課題に直面しました。\n",
      "\n",
      "主な失敗ポイント:\n",
      "\n",
      "1. 過剰な分解\n",
      "- 最初に30以上のマイクロサービスに分割\n",
      "- サービス間の依存関係が複雑化\n",
      "- システム全体のパフォーマンスが大幅に低下\n",
      "\n",
      "2. データ整合性の問題\n",
      "- 分散トランザクションの管理が困難\n",
      "- 取引データの不整合が発生\n",
      "- 金融システムでは致命的な問題となりうる\n",
      "\n",
      "3. チームの対応力不足\n",
      "- マイクロサービスの運用スキルが不十分\n",
      "- DevOpsプラクティスの未成熟\n",
      "- インフラ管理の複雑さに対応できない\n",
      "\n",
      "対処方法:\n",
      "\n",
      "1. サービスの再設計\n",
      "- サービスの粒度を見直し、10程度に統合\n",
      "- ドメイン駆動設計(DDD)の原則を適用\n",
      "- ビジネスドメインに基づいたサービス境界の再定義\n",
      "\n",
      "2. データ管理戦略の改善\n",
      "- イベントソーシング・パターンの導入\n",
      "- Kafkaを使用した非同期メッセージング\n",
      "- サガパターンによる分散トランザクションの管理\n",
      "\n",
      "3. チームのスキルアップ\n",
      "- Kubernetes、Docker研修の実施\n",
      "- マイクロサービスアーキテクチャのワークショップ\n",
      "- 継続的インテグレーション/デプロイメントの自動化\n",
      "\n",
      "4. 段階的な移行アプローチ\n",
      "- 全面的な移行ではなく、段階的な移行\n",
      "- 重要度の低いサービスから順次マイクロサービス化\n",
      "- モノリスと並行して運用\n",
      "\n",
      "5. モニタリングと可観測性の強化\n",
      "- 分散トレーシングツール(Jaeger)の導入\n",
      "- 詳細なログとメトリクスの収集\n",
      "- 障害検知と迅速な対応\n",
      "\n",
      "学んだ教訓:\n",
      "\n",
      "1. マイクロサービスは万能ではない\n",
      "2. 組織の成熟度とスキルを考慮する\n",
      "3. 段階的なアプローチが重要\n",
      "4. 明確な境界と適切な粒度が成功の鍵\n",
      "\n",
      "結果:\n",
      "- システムの安定性が向上\n",
      "- パフォーマンスの最適化\n",
      "- チームのスキル向上\n",
      "- より柔軟なアーキテクチャの実現\n",
      "\n",
      "この経験から、マイクロサービスへの移行は慎重に計画し、段階的に実行することの重要性を学びました。テクノロジーの選択だけでなく、組織文化とチームの能力も同様に重要だということを痛感しました。\n"
     ]
    }
   ],
   "source": [
    "question = \"マイクロサービスを採用して失敗した経験はありますか？どのように対処しましたか？\"\n",
    "ask_question(question, config, graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_history(config, graph):\n",
    "    messages = graph.get_state(config).values.get(\"messages\", [])\n",
    "    history = \"=== 面接履歴 ===\\n\\n\"\n",
    "    \n",
    "    for msg in messages:\n",
    "        name = getattr(msg, 'name', 'system')\n",
    "        speaker = {\"human\": \"👨‍💼 面接官\", \"trainee\": \"🤖 候補者\"}.get(name, \"📋 システム\")\n",
    "        history += f\"{speaker}: {msg.content}\\n\" + \"-\"*30 + \"\\n\"\n",
    "    \n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 面接履歴 ===\n",
      "\n",
      "👨‍💼 面接官: マイクロサービスの欠点は何ですか？\n",
      "------------------------------\n",
      "🤖 候補者: マイクロサービスアーキテクチャには、確かにいくつかの重要な欠点があります。私の経験を踏まえて、主な課題を説明します：\n",
      "\n",
      "1. 複雑性の増大\n",
      "マイクロサービスは、システム全体の運用複雑性を大幅に増加させます。以前、大規模な金融システムの再設計プロジェクトで、20以上のマイクロサービスを管理した経験から、以下の複雑性の課題を実感しました：\n",
      "- サービス間の通信管理\n",
      "- 分散トランザクションの調整\n",
      "- 障害発生時のトレースとデバッグの難しさ\n",
      "\n",
      "2. パフォーマンスのオーバーヘッド\n",
      "サービス間の通信は、ネットワークホップによって追加のレイテンシを生み出します。特に、\n",
      "- REST APIやgRPCによるサービス間通信\n",
      "- シリアライゼーションとデシリアライゼーションのオーバーヘッド\n",
      "- ネットワーク遅延の増加\n",
      "\n",
      "3. データ整合性の課題\n",
      "分散システムでは、データの一貫性を保つことが非常に難しくなります：\n",
      "- 分散トランザクションの実装の複雑さ\n",
      "- イベント駆動型アーキテクチャでの eventual consistency の管理\n",
      "- サガパターンなどの複雑な補償トランザクションの実装\n",
      "\n",
      "4. テストの複雑化\n",
      "マイクロサービスのテストは従来のモノリシックアプリケーションと比較して格段に難しくなります：\n",
      "- 統合テストの複雑性\n",
      "- モックとスタブの大量作成\n",
      "- エンドツーエンドのテストシナリオの設計\n",
      "\n",
      "5. インフラストラクチャの複雑さ\n",
      "運用面でも大きな課題があります：\n",
      "- Kubernetesなどのコンテナオーケストレーションの複雑な設定\n",
      "- 継続的デプロイメントの管理\n",
      "- モニタリングとロギングの複雑化\n",
      "\n",
      "6. チームの分散と認知的負荷\n",
      "組織的な観点からも課題があります：\n",
      "- サービス間の明確な境界の維持\n",
      "- チーム間のコミュニケーションオーバーヘッド\n",
      "- 各サービスの技術的負債の管理\n",
      "\n",
      "7. コストの増加\n",
      "インフラとメンテナンスのコストが増大します：\n",
      "- より多くのサーバーリソース\n",
      "- 複雑なモニタリングツール\n",
      "- 高度なスキルを持つエンジニアの必要性\n",
      "\n",
      "これらの欠点は、マイクロサービスが万能ではないことを示しています。プロジェクトの規模、チームの能力、ビジネス要件を慎重に評価し、適切なアーキテクチャを選択することが重要です。\n",
      "\n",
      "小規模なプロジェクトや、複雑性を管理できないチームの場合は、モノリシックアーキテクチャや、モノリスからマイクロサービスへの段階的な移行を検討するべきでしょう。\n",
      "------------------------------\n",
      "👨‍💼 面接官: マイクロサービスを採用して失敗した経験はありますか？どのように対処しましたか？\n",
      "------------------------------\n",
      "🤖 候補者: はい、かつて私が携わったプロジェクトで、マイクロサービスへの移行に苦労した経験があります。具体的な失敗と対処方法について詳しくお話しします。\n",
      "\n",
      "失敗の背景:\n",
      "私が以前勤めていた金融系のスタートアップで、モノリシックな基幹システムをマイクロサービスに急速に移行しようとした際に、多くの課題に直面しました。\n",
      "\n",
      "主な失敗ポイント:\n",
      "\n",
      "1. 過剰な分解\n",
      "- 最初に30以上のマイクロサービスに分割\n",
      "- サービス間の依存関係が複雑化\n",
      "- システム全体のパフォーマンスが大幅に低下\n",
      "\n",
      "2. データ整合性の問題\n",
      "- 分散トランザクションの管理が困難\n",
      "- 取引データの不整合が発生\n",
      "- 金融システムでは致命的な問題となりうる\n",
      "\n",
      "3. チームの対応力不足\n",
      "- マイクロサービスの運用スキルが不十分\n",
      "- DevOpsプラクティスの未成熟\n",
      "- インフラ管理の複雑さに対応できない\n",
      "\n",
      "対処方法:\n",
      "\n",
      "1. サービスの再設計\n",
      "- サービスの粒度を見直し、10程度に統合\n",
      "- ドメイン駆動設計(DDD)の原則を適用\n",
      "- ビジネスドメインに基づいたサービス境界の再定義\n",
      "\n",
      "2. データ管理戦略の改善\n",
      "- イベントソーシング・パターンの導入\n",
      "- Kafkaを使用した非同期メッセージング\n",
      "- サガパターンによる分散トランザクションの管理\n",
      "\n",
      "3. チームのスキルアップ\n",
      "- Kubernetes、Docker研修の実施\n",
      "- マイクロサービスアーキテクチャのワークショップ\n",
      "- 継続的インテグレーション/デプロイメントの自動化\n",
      "\n",
      "4. 段階的な移行アプローチ\n",
      "- 全面的な移行ではなく、段階的な移行\n",
      "- 重要度の低いサービスから順次マイクロサービス化\n",
      "- モノリスと並行して運用\n",
      "\n",
      "5. モニタリングと可観測性の強化\n",
      "- 分散トレーシングツール(Jaeger)の導入\n",
      "- 詳細なログとメトリクスの収集\n",
      "- 障害検知と迅速な対応\n",
      "\n",
      "学んだ教訓:\n",
      "\n",
      "1. マイクロサービスは万能ではない\n",
      "2. 組織の成熟度とスキルを考慮する\n",
      "3. 段階的なアプローチが重要\n",
      "4. 明確な境界と適切な粒度が成功の鍵\n",
      "\n",
      "結果:\n",
      "- システムの安定性が向上\n",
      "- パフォーマンスの最適化\n",
      "- チームのスキル向上\n",
      "- より柔軟なアーキテクチャの実現\n",
      "\n",
      "この経験から、マイクロサービスへの移行は慎重に計画し、段階的に実行することの重要性を学びました。テクノロジーの選択だけでなく、組織文化とチームの能力も同様に重要だということを痛感しました。\n",
      "------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "history = get_history(config, graph)\n",
    "\n",
    "print(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"interview_history_{thread_id}.txt\", \"w\") as f:\n",
    "    f.write(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
